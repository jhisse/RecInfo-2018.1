{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ['O peã e o caval são pec de xadrez. O caval é o melhor do jog.',\n",
    "    'A jog envolv a torr, o peã e o rei.',\n",
    "    'O peã lac o boi',\n",
    "    'Caval de rodei!',\n",
    "    'Polic o jog no xadrez.']\n",
    "stopwords = ['a', 'o', 'e', 'é', 'de', 'do', 'no', 'são']\n",
    "separadores = [' ', ',', '.', ';', '!', '?']\n",
    "q = 'xadrez peã caval torr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tudoMinusculo(documentos):\n",
    "    convertidos = []\n",
    "    for doc in documentos:\n",
    "        convertidos.append(doc.lower())\n",
    "    return convertidos\n",
    "\n",
    "m = tudoMinusculo(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converteSeparadores(documentos, separadores):\n",
    "    convertidos = []\n",
    "    for doc in documentos:\n",
    "        for separador in separadores:\n",
    "            doc = doc.replace(separador, ' ')\n",
    "        convertidos.append(doc)\n",
    "    return convertidos\n",
    "\n",
    "m = converteSeparadores(m, separadores)\n",
    "q = converteSeparadores([q], separadores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeniza(documentos):\n",
    "    convertidos = []\n",
    "    for doc in documentos:\n",
    "        convertidos.append(doc.split())\n",
    "    return convertidos\n",
    "\n",
    "tokens = tokeniza(m)\n",
    "tokens_consulta = tokeniza(q)\n",
    "\n",
    "N = len(m)\n",
    "tamanho_documentos = [len(doc) for doc in tokens]\n",
    "tamanho_medio = sum(tamanho_documentos)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopwords(tokens, stopwords):\n",
    "    tokens_sem_stopwords = []\n",
    "    for doc in tokens:\n",
    "        tokens_tmp = []\n",
    "        for palavra in doc:\n",
    "            if palavra not in stopwords:\n",
    "                tokens_tmp.append(palavra)\n",
    "        tokens_sem_stopwords.append(tokens_tmp)\n",
    "    return tokens_sem_stopwords\n",
    "\n",
    "tokens = removeStopwords(tokens, stopwords)\n",
    "\n",
    "tokens_consulta = removeStopwords(tokens_consulta, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraiTokensUnicos(tokens):\n",
    "    tokens_unicos = []\n",
    "    for doc in tokens:\n",
    "        for token in doc:\n",
    "            if token not in tokens_unicos:\n",
    "                tokens_unicos.append(token)\n",
    "    return tokens_unicos\n",
    "\n",
    "tokens_unicos = extraiTokensUnicos(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaTF(tokens, tokens_unicos, tokens_consulta):\n",
    "    matriz_tf = []\n",
    "    \n",
    "    for doc in tokens:\n",
    "        matriz = [0 for i in tokens_unicos]\n",
    "        for idx, token in enumerate(tokens_unicos):\n",
    "            if token in doc and token in tokens_consulta[0]:\n",
    "                matriz[idx] += doc.count(token)\n",
    "        matriz_tf.append(matriz)\n",
    "    return matriz_tf\n",
    "\n",
    "matriz_tf = calculaTF(tokens, tokens_unicos, tokens_consulta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaNi(matriz_tf):\n",
    "    ni = [0 for i in tokens_unicos]\n",
    "    for doc in matriz_tf:\n",
    "        for idx, freq in enumerate(doc):\n",
    "            if freq > 0:\n",
    "                ni[idx] += 1\n",
    "    return ni\n",
    "\n",
    "ni = calculaNi(matriz_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaBM25(matriz_tf, N, ni, tamanho_documentos, tamanho_medio, k=1, b=0.85):\n",
    "    bm25_doc = []\n",
    "    for idx, doc in enumerate(matriz_tf):\n",
    "        bm25 = 0\n",
    "        for idx2, freq in enumerate(doc):\n",
    "            bm25 += (((k+1)*freq)/(k*((1-b)+b*tamanho_documentos[idx]/tamanho_medio)+freq))*log((N-ni[idx2]+0.5)/(ni[idx2]+0.5))\n",
    "        bm25_doc.append(bm25)\n",
    "    return bm25_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34566788879097277, 0.6805600922685513, -0.3970474199161059, 0.45563948709122576, 0.3970474199161059]\n"
     ]
    }
   ],
   "source": [
    "BM25 = calculaBM25(matriz_tf, N, ni, tamanho_documentos, tamanho_medio, k=1, b=0.85)\n",
    "\n",
    "print(BM25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
